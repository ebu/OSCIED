#!/usr/bin/env bash

#**************************************************************************************************#
#              OPEN-SOURCE CLOUD INFRASTRUCTURE FOR ENCODING AND DISTRIBUTION : STORAGE
#
#  Authors   : David Fischer
#  Contact   : david.fischer.ch@gmail.com / david.fischer@hesge.ch
#  Project   : OSCIED (OS Cloud Infrastructure for Encoding and Distribution)
#  Copyright : 2012-2013 OSCIED Team. All rights reserved.
#**************************************************************************************************#
#
# This file is part of EBU/UER OSCIED Project.
#
# This project is free software: you can redistribute it and/or modify it under the terms of the
# GNU General Public License as published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# This project is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without
# even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with this project.
# If not, see <http://www.gnu.org/licenses/>
#
# Retrieved from:
#   svn co https://claire-et-david.dyndns.org/prog/OSCIED

set -o nounset # will exit if an unitialized variable is used

# Constants ========================================================================================

ECHO='juju-log' # Used by logicielsUbuntuUtils

# Configuration ====================================================================================

if [ "$(config-get verbose)" = 'true' ] ; then
  VERBOSE=0     # true
  set -o xtrace # for verbose logging to juju debug-log
else
  VERBOSE=1 # false
fi

# Charms paths
BASE_PATH=$(pwd)

# Charms files
VOLUME_FLAG="$BASE_PATH/volume_ok"

UNIT_ID="${JUJU_UNIT_NAME##*/}"
PRIVATE_IP=$(unit-get private-address)
VOLUME_NAME="medias_volume_$UNIT_ID"
REPLICA_COUNT=$(config-get replica_count)

# Utilities ========================================================================================

PEER_HELPER='/usr/share/charm-helper/sh/peer.sh'
if [ -f "$PEER_HELPER" ]; then
  . "$PEER_HELPER"
fi

# HOOKS : Charm Setup ==============================================================================

hook_install()
{
  techo ' Storage - install'

  apt-add-repository -y ppa:charmers/charm-helpers || \
    xecho 'Unable to add charms helpers repository' 1

  eval $update
  eval $upgrade

  pecho 'Install and configure Network Time Protocol'
  eval $install ntp || xecho 'Unable to install ntp' 2
  eval $service ntp restart || xecho 'Unable to restart ntp service' 3

  pecho 'Install Charms helpers and GlusterFS Server'
  eval $install charm-helper-sh glusterfs-server nfs-common || xecho 'Unable to install packages' 4

  if [ $REPLICA_COUNT -eq 1 ]; then
    pecho "Create and start medias volume $VOLUME_NAME with 1 brick (no redudancy at all)"
    gluster volume create "$VOLUME_NAME" "$PRIVATE_IP:/exp1" || \
      xecho "Unable to create medias volume $VOLUME_NAME on brick $PRIVATE_IP:/exp1" 5
    gluster volume start "$VOLUME_NAME" || xecho "Unable to start volume $VOLUME_NAME" 6
    gluster volume info
    touch "$VOLUME_FLAG" || xecho 'Unable to create flag' 7
  else
    recho "Waiting for $((REPLICA_COUNT-1)) peers to create and start medias volume $VOLUME_NAME"
  fi

  juju-log 'Expose GlusterFS Server service'
  open-port 111/tcp     # Is used for portmapper, and should have both TCP and UDP open
  open-port 24007/tcp   # For the Gluster Daemon
  #open-port 24008/tcp  # Infiniband management (optional unless you are using IB)
  open-port 24009/tcp   # We have only 1 storage brick (24009-24009)
  #open-port 38465/tcp  # For NFS (not used)
  #open-port 38466/tcp  # For NFS (not used)
  #open-port 38467/tcp  # For NFS (not used)
}

hook_uninstall()
{
  techo 'Storage - uninstall'

  hook_stop

  eval $purge glusterfs-server nfs-common
  eval $autoremove
}

# HOOKS : Charm Service ============================================================================

hook_start()
{
  techo 'Storage - start'

  if ! service glusterfs-server status | grep -q 'running'; then
    service glusterfs-server start || xecho 'Unable to start GlusterFS Server' 1
  fi
}

hook_stop()
{
  techo 'Storage - stop'

  if service glusterfs-server status | grep -q 'running'; then
    service glusterfs-server stop || xecho 'Unable to stop GlusterFS Server' 1
  fi
}

# HOOKS : Provides Storage =========================================================================

hook_storage_relation_joined()
{
  techo 'Storage - storage relation joined'

  # Send filesystem type, mount point & options only if volume is created and started
  if [ -f "$VOLUME_FLAG" ]
  then relation-set fstype='glusterfs' mountpoint="$VOLUME_NAME" options=''
  else relation-set fstype='' mountpoint='' options=''
  fi
}

# HOOKS : Handle Clustering of Storage =============================================================

debug_peer_relation()
{
  if [ $VERBOSE -eq 0 ]; then
    mecho '[DEBUG] Peer relation settings:'; relation-get
    mecho '[DEBUG] Peer relation members:';  relation-list
  fi
}

hook_peer_relation_joined()
{
  techo 'Storage - peer relation joined'
  debug_peer_relation

  if ! ch_peer_i_am_leader; then
    pecho "As slave, stop and delete my own volume $VOLUME_NAME"
    if gluster volume info  "$VOLUME_NAME" > /dev/null; then
      gluster volume stop   "$VOLUME_NAME" || xecho "Unable to stop volume $VOLUME_NAME"  1
      gluster volume delete "$VOLUME_NAME" || xecho "Unable to delete volume VOLUME_NAME" 2
      rm -f "$VOLUME_FLAG" || xecho 'Unable to remove flag' 3
    fi
  fi
}

hook_peer_relation_changed()
{
  techo 'Storage - peer relation changed'
  debug_peer_relation

  # Get configuration from the relation
  ip=$(relation-get private-address)

  mecho "Peer IP is $ip"
  if [ ! "$ip" ]; then
    recho 'Waiting for complete setup'
    exit 0
  fi

  # FIXME close previously opened ports if some bricks leaved ...
  pecho 'Open required ports'
  count=1
  bricks="$PRIVATE_IP:/exp1"
  for peer in $(relation-list)
  do
    open-port $((24009+count))/tcp  # Open required
    peer_ip=$(relation-get private-address "$peer")
    bricks="$bricks $peer_ip:/exp1"
    count=$((count+1))
  done

  if ch_peer_i_am_leader; then
    pecho "As leader, probe remote peer $ip"
    gluster peer probe "$ip" || xecho "Unable to probe peer $ip" 1

    if [ $count -lt $REPLICA_COUNT ]; then
      recho "Waiting for $((REPLICA_COUNT-1)) peers to create and start medias volume $VOLUME_NAME"
    else
      pecho "Create and start medias volume $VOLUME_NAME with $count bricks"
      mecho "Bricks are $bricks"
      gluster volume create "$VOLUME_NAME" replica "$REPLICA_COUNT" transport tcp $bricks || \
        xecho "Unable to create medias volume $VOLUME_NAME" 2
      gluster volume start "$VOLUME_NAME" || xecho "Unable to start volume $VOLUME_NAME" 3
      gluster volume info
      touch "$VOLUME_FLAG" || xecho 'Unable to create flag' 4
    fi
    # FIXME handle addition of more peers when volume is already created and started !
    #gluster volume add-brick "$VOLUME_NAME" "$ip:/$BRICK_NAME" || \
    #  xecho 'Unable to add remote peer brick to medias volume' 4
  fi
}

hook_peer_relation_broken()
{
  techo 'Storage - peer relation broken'
  debug_peer_relation

  recho 'FIXME NOT IMPLEMENTED'
}
